model:
  type: resnet50
  hidden_units: 256
  dropout_rate: 0.5
  activation: relu
training:
  learning_rate: 0.001
  batch_size: 32
  epochs: 100
  optimizer: adam
  weight_decay: 0.0001
data:
  augmentation:
    flip: true
    rotation_range: 30
    zoom_range: 0.2
  train_split: 0.8
  validation_split: 0.1
regularization:
  dropout_rate: 0.5
  l2_lambda: 0.01
logging:
  level: INFO
  dir: ./logs

checkpoint:
  save_dir: ./checkpoints
  save_freq: 5
transfer_learning:
  use_pretrained: true
  freeze_layers: all
optimization:
  lr_schedule:
    type: step_decay
    decay_rate: 0.1
    decay_steps: 10
hardware:
  device: gpu
  multi_gpu: 2
sweep: # lists of parameter values to experiment with
  learning_rate: [0.001, 0.01, 0.1]
  batch_size: [16, 32, 64]
